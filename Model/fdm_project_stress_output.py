# -*- coding: utf-8 -*-
"""FDM_PROJECT_stress_output.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PfmmfUbKNsZtviseQvdBm8HyXAww5TtQ
"""

from google.colab import drive

drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Y3.S1 FDM

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder

# Load the dataset
data = pd.read_csv("student mental health_1.csv")

# Data Preprocessing

# Feature Engineering
# 1. Age Groups
data['Age_Group'] = pd.cut(data['Age'], bins=[0, 19, 29, 39, float('inf')],
                          labels=['Teen', 'Young Adult', 'Adult', 'Senior'])
# 2. Credit Load Categories
data['Credit_Load_Category'] = pd.cut(data['Semester_Credit_Load'], bins=[15, 20, 25, float('inf')],
                                      labels=['Low', 'Medium', 'High'])
# 3. CGPA Bins
data['CGPA_Category'] = pd.cut(data['CGPA'], bins=[0, 3, 3.5, 4, float('inf')],
                              labels=['Low', 'Medium', 'High', 'Excellent'])

#data['Composite_Score'] = data['Depression_Score'] + data['Anxiety_Score']

# Handle Missing Data

# Numerical columns
numerical_columns = ['Age', 'CGPA', 'Stress_Level', 'Depression_Score', 'Anxiety_Score', 'Financial_Stress', 'Semester_Credit_Load']
data[numerical_columns] = data[numerical_columns].fillna(data[numerical_columns].mean())

# Categorical columns
categorical_columns = [
    'Course', 'Gender', 'Sleep_Quality', 'Physical_Activity', 'Diet_Quality', 'Social_Support',
    'Relationship_Status', 'Substance_Use', 'Counseling_Service_Use', 'Family_History',
    'Chronic_Illness', 'Extracurricular_Involvement', 'Residence_Type',
    'Age_Group', 'Credit_Load_Category', 'CGPA_Category']

for col in categorical_columns:
    data[col].fillna(data[col].mode()[0], inplace=True)

# Encode Categorical Data
label_encoder = LabelEncoder()
for col in categorical_columns:
    data[col] = label_encoder.fit_transform(data[col])

# Remove duplicate records
data = data.drop_duplicates()

# Handle Outliers
summary = data.describe()
Q1 = summary.loc['25%']
Q3 = summary.loc['75%']
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
is_outlier = ((data < lower_bound) | (data > upper_bound)).any(axis=1)
data = data[~is_outlier]

# Map Stress_Level to binary values
stress_level_mapping = {0: 0, 1: 1, 2: 1, 3: 3, 4: 2, 5: 3}

# Convert the target columns to binary
data['Stress_Level'] = data['Stress_Level'].replace(stress_level_mapping)

# Split the data into features (X) and the target (y)
X = data.drop(columns=['Stress_Level'])
y = data['Stress_Level']

# Split the data into a training set and a testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""find dependencies"""

# Calculate the correlation matrix
correlation_matrix = data.corr()

# Get the correlation of all columns with "Stress_Level"
correlation_with_stress_level = correlation_matrix['Stress_Level']

# Sort the columns by their correlation with "Stress_Level"
sorted_correlation = correlation_with_stress_level.abs().sort_values(ascending=False)

print("Correlation with Stress_Level:\n", sorted_correlation)

from sklearn.feature_selection import mutual_info_classif

# Assuming X contains your feature matrix and y contains 'Stress_Level'
mutual_info = mutual_info_classif(X, y)
mutual_info_series = pd.Series(mutual_info, index=X.columns)
mutual_info_series.sort_values(ascending=False, inplace=True)
print(mutual_info_series)

"""model 1"""

# Hyperparameter Tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

#grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1)
#grid_search.fit(X_train, y_train)
#best_params = grid_search.best_params_
best_params = {'max_depth': 5,
 'min_samples_leaf': 4,
 'min_samples_split': 10,
 'n_estimators': 100}

# Train a random forest classifier model with the best hyperparameters
best_model = RandomForestClassifier(random_state=42, **best_params)
best_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = best_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Model Accuracy:", accuracy)
print("Best Hyperparameters:", best_params)
print("Classification Report:\n", report)

best_params

"""model 2"""

import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV

# Hyperparameter Tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15],
    'learning_rate': [0.01, 0.1, 0.2],
}

grid_search = GridSearchCV(XGBClassifier(random_state=42), param_grid, cv=3, n_jobs=-1)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_

# Train an XGBoost classifier model with the best hyperparameters
best_model = XGBClassifier(random_state=42, **best_params)
best_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = best_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Model Accuracy:", accuracy)
print("Best Hyperparameters:", best_params)
print("Classification Report:\n", report)

